{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8d3e3d-0884-4e0b-94bc-385025ae7f64",
   "metadata": {},
   "source": [
    "# Making Datasets from Multiple PoCs at Once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e7ea4-2323-4b4c-9302-79bb5668a219",
   "metadata": {},
   "source": [
    "### Some parameter needed for generating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eff33c0-e796-4a32-a611-529bd5aa2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set First Date\n",
    "first_day = (1, 11, 2022)\n",
    "# Set Last Date\n",
    "# Do not use the current date since it is not available until the next day\n",
    "last_day = (30, 4, 2024)\n",
    "\n",
    "# list of required PoCs\n",
    "pocs = [\n",
    "        'ALB0331',   ## Auckland\n",
    "        'HAM0331',   ## Hamilton\n",
    "        'WIL0331',   ## Wellington\n",
    "        'ISL0661',   ## ChristChurch\n",
    "        'SDN0331',   ## Dunedin\n",
    "        'STK0331',   ## Nelson\n",
    "       ]\n",
    "\n",
    "# list of abstract targets (mean or median)\n",
    "ts = ['Avg$PerMWHr', 'Med$PerMWHr']\n",
    "\n",
    "# list of required amount of delays, each unit 30 mins\n",
    "delay = [\n",
    "    1,  ## 30 mins delay\n",
    "    8,  ## 4 hrs delay\n",
    "    12,  ## 6 hrs delay\n",
    "    48,  ## 24 hrs delay\n",
    "    ]\n",
    "\n",
    "# set to True if ARFF files are also required\n",
    "arff_option = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa5ffa1-fbfe-4d25-85da-2e28e13c1c27",
   "metadata": {},
   "source": [
    "### Also defining some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a161f68-95f3-47ee-85a7-0f17834d65c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "target = 'DollarsPerMegawattHour'\n",
    "boolean_dict = {'Y':1, 'N':0}\n",
    "island_dict = {'NI':1, 'SI':0}\n",
    "\n",
    "def read_energy_csv(filename, PoC = None):\n",
    "  df = pd.read_csv(filename)\n",
    "  if PoC != None:\n",
    "    df = df[df['PointOfConnection'] == PoC]\n",
    "    df = df.drop(columns = ['PointOfConnection'])\n",
    "  df['DateTime'] = [datetime.strptime(date, \"%Y-%m-%dT%H:%M:%S.000%z\") for date in df['PublishDateTime']]\n",
    "  df['IsProxyPriceFlag'] = [boolean_dict[c] for c in df['IsProxyPriceFlag']]\n",
    "  df['Date'] = [p.date() for p in df['DateTime']]\n",
    "  df['Time'] = [p.time() for p in df['DateTime']]\n",
    "  df['IntTime'] = [t.hour*3600+t.minute*60+t.second for t in df['Time']]\n",
    "  df['Year'] = [d.year for d in df['Date']]\n",
    "  df['Month'] = [d.month for d in df['Date']]\n",
    "  df['Day'] = [d.day for d in df['Date']]\n",
    "  df = df.drop(columns = ['Island', 'Date', 'Time'])\n",
    "  return df\n",
    "\n",
    "def num_string(x, length = 2):\n",
    "  string = str(x)\n",
    "  while len(string) < length:\n",
    "    string = \"0\"+string\n",
    "  return string\n",
    "\n",
    "def date_string(day, month, year, length = 2):\n",
    "  return (num_string(year,length)+\n",
    "          num_string(month,length)+\n",
    "          num_string(day,length))\n",
    "\n",
    "def make_url(day, month, year = 2023):\n",
    "  year_string = date_string(day, month, year)\n",
    "  s = \"https://www.emi.ea.govt.nz/Wholesale/Datasets/DispatchAndPricing/DispatchEnergyPrices/\"\n",
    "  s = s+str(year)+\"/\"+year_string+\"_DispatchEnergyPrices.csv\"\n",
    "  return s\n",
    "\n",
    "seconds_in_a_day = 86400\n",
    "def cyclic_encoder(x, min = 0, max = seconds_in_a_day):\n",
    "  lambd = [2*np.pi*(n-min)/(max-min) for n in x]\n",
    "  sin_x = [np.sin(n) for n in lambd]\n",
    "  cos_x = [np.cos(n) for n in lambd]\n",
    "  return (sin_x, cos_x)\n",
    "\n",
    "def csv_to_arff(csv_file_path, arff_file_path, relation_name='relation'):\n",
    "    \n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Open the ARFF file for writing\n",
    "    with open(arff_file_path, 'w') as f:\n",
    "        # Write the relation name\n",
    "        f.write(f\"@relation {relation_name}\\n\\n\")\n",
    "        \n",
    "        # Write attribute names and types\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'object':\n",
    "                f.write(f\"@attribute {col} nominal\\n\")\n",
    "            elif df[col].dtype == 'int64':\n",
    "                f.write(f\"@attribute {col} numeric\\n\")\n",
    "            elif df[col].dtype == 'float64':\n",
    "                f.write(f\"@attribute {col} numeric\\n\")\n",
    "            else:\n",
    "                f.write(f\"@attribute {col} unknown\\n\")\n",
    "\n",
    "        f.write(\"\\n@data\\n\")\n",
    "\n",
    "        # Write the data\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(','.join(map(str, row.values)) + '\\n')\n",
    "\n",
    "def make_targets_with_delay(dict, delay: int = 1, target='Avg$PerMWHr'):\n",
    "    not_target = 'Med$PerMWHr' if target == 'Avg$PerMWHr' else 'Avg$PerMWHr'\n",
    "    target_col = dict['Avg$PerMWHr']\n",
    "    previous_tar_str = 'Prev'+target\n",
    "    previous_not_tar_str = 'Prev'+not_target\n",
    "    targets = dict[target]\n",
    "    previous_col = list(dict[previous_tar_str])\n",
    "    previous_other_col = list(dict[previous_not_tar_str])\n",
    "    for i in range(delay -1):\n",
    "        previous_col.insert(0,0)\n",
    "        previous_col.pop()\n",
    "        previous_other_col.insert(0,0)\n",
    "        previous_other_col.pop()\n",
    "    df = dict.drop(columns=target)\n",
    "    df = dict.drop(columns=not_target)\n",
    "    df[target] = targets\n",
    "    df[previous_tar_str] = previous_col\n",
    "    df[previous_not_tar_str] = previous_other_col\n",
    "\n",
    "    # re-order the columns to put the target at the end\n",
    "    column_to_move = target\n",
    "    cols = [col for col in df.columns if col != column_to_move]\n",
    "    re_ordered = cols + [column_to_move]\n",
    "    df = df[re_ordered]\n",
    "    \n",
    "    df = df.iloc[delay - 1:]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "month_date_dict = {1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30,\n",
    "                   7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31}\n",
    "\n",
    "dates = [first_day]\n",
    "\n",
    "while dates[-1] != last_day:\n",
    "  last_date = dates[-1]\n",
    "  date = (last_date[0]+1, last_date[1], last_date[2])\n",
    "  if date[0] > month_date_dict[date[1]]:\n",
    "    date = (1, date[1]+1, date[2])\n",
    "  if date[1] > 12:\n",
    "    date = (1, 1, date[2]+1)\n",
    "  dates.append(date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dff53-989e-4d43-9576-e0452890a98f",
   "metadata": {},
   "source": [
    "# Download and Make Datasets (could take quite long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c781ce48-50c4-4cfa-99a0-b1970603f916",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m day, month, year \u001b[38;5;129;01min\u001b[39;00m dates:\n\u001b[1;32m      5\u001b[0m   url \u001b[38;5;241m=\u001b[39m make_url(day, month, year)\n\u001b[0;32m----> 6\u001b[0m   df \u001b[38;5;241m=\u001b[39m read_energy_csv(url, PoC \u001b[38;5;241m=\u001b[39m poc)\n\u001b[1;32m      7\u001b[0m   dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m      9\u001b[0m dfs_loaded \u001b[38;5;241m=\u001b[39m [df\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m dfs]\n",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mread_energy_csv\u001b[0;34m(filename, PoC)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_energy_csv\u001b[39m(filename, PoC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 14\u001b[0m   df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filename)\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m PoC \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPointOfConnection\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m PoC]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    719\u001b[0m     path_or_buf,\n\u001b[1;32m    720\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    721\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    722\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    723\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    724\u001b[0m )\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "for p in pocs:\n",
    "    dfs = []\n",
    "    poc = p\n",
    "    for day, month, year in dates:\n",
    "      url = make_url(day, month, year)\n",
    "      df = read_energy_csv(url, PoC = poc)\n",
    "      dfs.append(df)\n",
    "    \n",
    "    dfs_loaded = [df.copy() for df in dfs]\n",
    "    dfs_transformed = []\n",
    "\n",
    "    for df in dfs:\n",
    "      df_t = df.copy()\n",
    "      avg = df_t.groupby([\"TradingPeriod\"]).mean(numeric_only=True)['DollarsPerMegawattHour']\n",
    "      df_t = df_t.groupby([\"TradingPeriod\"]).median(numeric_only=True)\n",
    "      df_t['Avg$PerMWHr'] = avg\n",
    "      dfs_transformed.append(df_t)\n",
    "    \n",
    "    full_data = pd.concat(dfs_transformed)\n",
    "    full_data.columns = full_data.columns.str.replace('DollarsPerMegawattHour',\n",
    "                                                      'Med$PerMWHr')\n",
    "    \n",
    "    avgs = [a for a in full_data['Avg$PerMWHr']]\n",
    "    meds = [m for m in full_data['Med$PerMWHr']]\n",
    "    avgs.insert(0, avgs[0])\n",
    "    avgs.pop()\n",
    "    meds.insert(0, meds[0])\n",
    "    meds.pop()\n",
    "    full_data['PrevAvg$PerMWHr'] = avgs\n",
    "    full_data['PrevMed$PerMWHr'] = meds\n",
    "    \n",
    "    full_data = full_data.drop(columns = 'IntTime')\n",
    "    full_data['SinPeriod'], full_data['CosPeriod'] = cyclic_encoder(full_data.index, max = 48)\n",
    "    date_col = []\n",
    "    for day, month, period in zip(full_data['Day'], full_data['Month'], full_data.index):\n",
    "      value = day + (period-1)/48\n",
    "      for m in range(1, int(month)):\n",
    "        value += month_date_dict[m]\n",
    "      date_col.append(value)\n",
    "    full_data['SinDate'], full_data['CosDate'] = cyclic_encoder(date_col, max = 365)\n",
    "    \n",
    "    for column in full_data.columns:\n",
    "      full_data[column] = [round(d, 8) for d in full_data[column]]\n",
    "    \n",
    "    filename = \"all_\"+poc+\"_data.csv\"\n",
    "    \n",
    "    if not os.path.exists('./full_data'):\n",
    "        os.makedirs('./full_data')\n",
    "    \n",
    "    full_data.to_csv('./full_data/'+filename)\n",
    "\n",
    "    if not os.path.exists('./datasets'):\n",
    "        os.makedirs('./datasets')\n",
    "    \n",
    "    for t in ts:\n",
    "        for d in delay:\n",
    "            if not os.path.exists(f'./datasets/{poc}'):\n",
    "                os.makedirs(f'./datasets/{poc}')\n",
    "            delay_in_hour = f\"{(d/2):.0f}\" if (d/2).is_integer() else f\"{(d/2):.1f}\"\n",
    "            df = make_targets_with_delay(pd.read_csv(f'./full_data/all_{p}_data.csv'), delay=d, target=t)\n",
    "            df.to_csv(\n",
    "                f'./datasets/{poc}/{poc}_{t[:3].lower()}_{delay_in_hour}hr.csv', index=False\n",
    "            )\n",
    "            if arff_option:\n",
    "                csv_to_arff(\n",
    "                    f'./datasets/{poc}/{poc}_{t[:3].lower()}_{delay_in_hour}hr.csv', \n",
    "                    f'./datasets/{poc}/{poc}_{t[:3].lower()}_{delay_in_hour}hr.arff', \n",
    "                    relation_name=f'relation: PoC: {poc}; Target: {t}; Delay: {delay_in_hour}hr'\n",
    "                )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6855c0c6-a43f-493e-a7b0-d95e5902a5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
